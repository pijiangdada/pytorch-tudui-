# p14 Torchvision中数据集的使用



## 1 简介pytorch中的数据集（cv方向）

![image-20220916172838559](typora-user-images\image-20220916172838559.png)



点开后在左上角点击version为0.9.0切换至0.9.0的pytorch界面：

![image-20220916173337724](typora-user-images\image-20220916173337724.png)

然后再点击datasets找出常用的cv相关的数据集：

![image-20220916173434740](typora-user-images\image-20220916173434740.png)

其中，介绍了几个常用的模块：

1、coco：常用的目标检测数据集（很大30多G）

2、MINIST：手写文字数据集

3、CIFAR10：用于物体识别的数据集



4、torchvision.models中：提供了几个常用的已经训练好的，可以直接使用的神经网络模型！

![image-20220916173834449](typora-user-images\image-20220916173834449.png)



5、torchvision.utils提供了许多常用的小工具



## 2 dataset和transforms的联合使用实战

1、在pycharm中新建一个p14_dataset_transform.py文件

2、编辑下载CIFAR10数据集的代码：

CIFAR10的数据集介绍：

![image-20220916182514626](typora-user-images\image-20220916182514626.png)

![image-20220916174912031](typora-user-images\image-20220916174912031.png)

分别解释一下，这几个参数的含义：

①root：数据集的存放地址

②train：若为true，则是训练数据集，否则是测试数据集

③target_transform：存放需要预处理图片的方法的对象

④download：若为true，则从网络上下载数据集；否则需要自己准备好数据集在对应的文件中



3、正式编辑下载的train和test数据集的代码：

```
import torchvision

train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, download=True)
```



4、右键执行，观察结果，下载成功了：

![image-20220916175513741](typora-user-images\image-20220916175513741.png)



5、如果下载速度慢的话，可以复制控制台给的下载链接，在迅雷（或者其他下载器）中进行下载

下载好后，把下载后的压缩包复制粘贴在root参数标识的目录文件下面（这里的目录文件为dataset）

![image-20220916185315788](typora-user-images\image-20220916185315788.png)

然后下载的代码仍然不变（download仍然为true），运行，系统会自动检查并解压文件，结果如下：

![image-20220916185434314](typora-user-images\image-20220916185434314.png)



6、观察数据集的文件目录

![image-20220916175909830](typora-user-images\image-20220916175909830.png)

如果我们要下载的数据集官方没有给链接，可以ctrl+鼠标左键的方式在官方文档中找链接

![image-20220916185533321](typora-user-images\image-20220916185533321.png)



## 3 下载好后数据集的组织结构



首先声明，这个CIFAR10数据集是完全按照之前所讲的数据集的存放组织来组织的，因此许多之前自己实现的方法，在这里仍然适用！

贴一个之前的getitem的代码：

```
    def __getitem__(self, idx):
        img_name = self.img_path[idx] # 获取对应index下的图片的名称
        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name) # 拼接、获取当前图片的最完整的路径
        img = Image.open(img_item_path)  # 正式打开图片，并将图片的所有参数传递给img对象中
        label = self.label_dir # 获取当前图片的标签
        return img, label  # 返回图片对象，和图片标签
```



（不知道内部如何实现的没关系，只要知道接口如何使用即可！）



使用代码查看数据的第一个结构：

```
import torchvision

train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, download=True)

print(test_set[0])
```

![image-20220916181159858](typora-user-images\image-20220916181159858.png)

其中打印出来的呢个“3”表示该图片的类别是classes类别列表中的第三个（即：猫）

![image-20220916181447678](typora-user-images\image-20220916181447678.png)

代码实践：

```
import torchvision

train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, download=True)

img, target = test_set[0] # 之前有讲过，这里的getitem方法和之前实现过的一模一样
print(img)
print(target)
print(test_set.classes[target])
img.show()
```

效果如下：

![image-20220916182233092](typora-user-images\image-20220916182233092.png)

同事显示一张图片出来



## 4 CIFAR10下载好后和transforms的联动使用

### ①转换为tensor类型的图片

这里就是编辑之前

![image-20220916182735159](typora-user-images\image-20220916182735159.png)

的第三个函数：如何对下载好的图片进行预处理



代码实战：

```
import torchvision

dataset_transform = torchvision.transforms.Compose([ # 实例化对图片进行预处理操作的类，作为之后加载数据的第三个参数的形式出现
    torchvision.transforms.ToTensor() # 将下载的图片预处理，全都变为tensor张量的格式
])

train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, transform=dataset_transform, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, transform=dataset_transform, download=True)

print(test_set[0])
```

效果展示，成功切换为了tensor的形式：

![image-20220916183331797](typora-user-images\image-20220916183331797.png)

### ②用SummaryWriter进行对图片的打印

1、在pycharm中编写代码：

```
import torchvision
from torch.utils.tensorboard import SummaryWriter

dataset_transform = torchvision.transforms.Compose([ # 实例化对图片进行预处理操作的类，作为之后加载数据的第三个参数的形式出现
    torchvision.transforms.ToTensor() # 将下载的图片预处理，全都变为tensor张量的格式
])

train_set = torchvision.datasets.CIFAR10(root="./dataset", train=True, transform=dataset_transform, download=True)
test_set = torchvision.datasets.CIFAR10(root="./dataset", train=False, transform=dataset_transform, download=True)

# print(test_set[0])

writer = SummaryWriter("P14_Writer")  # 设置打印图片的文件夹
for i in range(10):
    img, target = test_set[i] # 获取每个图片的对象和标签
    writer.add_image("test_set", img, i) #打印每个图片到一张表的不同step中

writer.close()
```

2、在控制台启动打印系统：（注意 tensorboard命令的logdir参数要更改！！！）

![image-20220916184659476](typora-user-images\image-20220916184659476.png)

3、效果如下：

![image-20220916184757683](typora-user-images\image-20220916184757683.png)



# p15 dataloader的使用

## 1 查看dataloader的官方文档

在官网https://pytorch.org/ 的doc部分的左上角，选择1.8.1版本的pytorch，再搜索dataloader

![image-20220916193128132](typora-user-images\image-20220916193128132.png)

点击：[torch.utils.data.DataLoader](https://pytorch.org/docs/1.8.1/data.html?highlight=dataloader#torch.utils.data.DataLoader) 

看到：

![image-20220916193306146](typora-user-images\image-20220916193306146.png)

每个参数的具体解释：

①dataset：要加载的数据集

②batch_size：表示每次抓取的图片数量

③shuffle：若为true，则下一次需要打乱图片顺序

⑤num_workers：多进程还是单个进程（默认为0，表示主进程，且在win系统中该值大于零会报错BrokenPipeError）

⑥drop_last：当batch_size除不尽时，余数的图片是否舍去



## 2 代码实战——初写dataloader

1、在pycharm中打开新的dataloader.py文件，使用CIFAR10的数据集（只用test数据即可）

2、加载数据集时需要转换为tensor类型的图片

```
import torchvision

# 准备测试的数据集
from torch.utils.data import DataLoader # 导入dataloader的包，注意这个包的来源位置！

test_data = torchvision.datasets.CIFAR10("./dataset", train=False, transform=torchvision.transforms.ToTensor(), download=True) #下载数据集
test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=0, drop_last=False)

# 打印测试集中第一张图片的规格和标签
img, target = test_data[0]
print(img.shape)
print(target)


```



结果如下：

![image-20220916194919026](typora-user-images\image-20220916194919026.png)

## 3 图解batch_size的作用

就是成批量的打包imgs和targets然后返回：

![image-20220916195208128](typora-user-images\image-20220916195208128.png)

## 4 打印出dataloader（batchsize=4时）返回的对象的组织结构

代码如下：

```
import torchvision

# 准备测试的数据集
from torch.utils.data import DataLoader # 导入dataloader的包，注意这个包的来源位置！

test_data = torchvision.datasets.CIFAR10("./dataset", train=False, transform=torchvision.transforms.ToTensor(), download=True) #下载数据集
test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=0, drop_last=False)

for data in test_loader:
    imgs, targets = data
    print(imgs.shape)
    print((targets))
```

结果如下：

![image-20220916195748084](typora-user-images\image-20220916195748084.png)

（补充：test_loader对象中有一个sampler属性，表示batchsize=4是否随机抓取4张图片）

## 5 使用tensorboard打印出load后的batch的图片

1、代码编写：

```
import torchvision

# 准备测试的数据集
from torch.utils.data import DataLoader # 导入dataloader的包，注意这个包的来源位置！
from torch.utils.tensorboard import SummaryWriter

test_data = torchvision.datasets.CIFAR10("./dataset", train=False, transform=torchvision.transforms.ToTensor(), download=True) #下载数据集
test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle=True, num_workers=0, drop_last=False)

writer = SummaryWriter("P15_dataloader")
step = 0 # 用于打印图片的时候展示步数
for data in test_loader:
    imgs, targets = data
    writer.add_images("test_data", imgs, step) # #### 注意这里是复数，因为每次添加的不只是一张图片了！
    step = step + 1

writer.close()
```

2、在终端打开图片显示

在控制台的工作目录下、自己的pytorch环境下，输入

```
tensorboard --logdir="P15_dataloader"
```

3、打开网页，显示如下，发现每4张图片为一个step了

![image-20220916201023795](typora-user-images\image-20220916201023795.png)

（补充：若droplast参数设置为false，说明不抛弃余数的图片，最后一个step就可以有<3的图片数量；反之，会把余数抛弃掉）



# p16 神经网络的基本骨架——nn.Module的使用

## 1 查看官方文档

在官网https://pytorch.org/ 的doc部分的左上角，选择1.8.1版本的pytorch，点击torch.nn栏

[torch.nn — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/nn.html)

![image-20220916201831456](typora-user-images\image-20220916201831456.png)

对其中的各个类别的解释：

①Containers：对pytorch的神经网络定义骨架

②convolution layers：卷积层

③pooling layers：池化层

④padding layers：

⑤Non-linear Activations：非线性激活

⑥Normalization Layers：正则化层

等等等



## 2 详细介绍container

![image-20220916202841564](typora-user-images\image-20220916202841564.png)

查看model的官方文档：

[Module — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/generated/torch.nn.Module.html#torch.nn.Module)

讲解示例：

```
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module): # 继承父类
    def __init__(self):
        super(Model, self).__init__() # 运行父类的init方法
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, input): # 编写前向传播的函数
        x = F.relu(self.conv1(input)) # 对input进行一次卷积+非线性的处理
        return F.relu(self.conv2(input)) # 在进行一次卷积+非线性的处理，并返回
```

forward函数图解：（forward函数，应该在每一个模型中进行重写！）

![image-20220916203511629](typora-user-images\image-20220916203511629.png)

## 3 代码实践

1、在pycharm中新建一个p16_nn_model.py文件

2、编写继承的代码：

```
from torch import nn

class lzp(nn.Module): # 自己定义自己的模型，继承model类
```

3、init和forward函数的编写：

方法一：老老实实自己手敲



方法二：利用pycharm的快捷工具来重写这两个方法

![image-20220916204608448](typora-user-images\image-20220916204608448.png)

![image-20220916204642309](typora-user-images\image-20220916204642309.png)

![image-20220916204708608](typora-user-images\image-20220916204708608.png)

![image-20220916204715797](typora-user-images\image-20220916204715797.png)

4、编写代码：

```
import torch
from torch import nn

class Lzp(nn.Module): # 自己定义自己的模型，继承model类
    def __init__(self) -> None:
        super().__init__()  # 直接复现模版中的init函数

    def forward(self, input):
        output = input + 1
        return output


lzp = Lzp() # 实例化我们新建的类
x = torch.tensor(1.0) # 将1.0这个数，转化为一个tensor张量,tensor函数就是将输入直接转化为张量
output = lzp(x) # 将x张量作为输入进行模型的训练，结果返回给output
print(output)
```

结果显示：`2.`说明成功了

5、注意，这个forward函数是在

```
output = lzp(x) # 将x张量作为输入进行模型的训练，结果返回给output
```

这一行执行的，所以这个forward函数的使用方法类似于call函数，就是调用这个实体类的时候自动运行的函数





# p17 土堆讲卷积

## 1 查看官方文档

在官网，点击doc的pytorch，左上角切换到1.8.1版本

在torch.nn中找到convolution layers，即为卷积层的官方文档

![image-20220917094145246](typora-user-images\image-20220917094145246.png)

![image-20220917094257950](typora-user-images\image-20220917094257950.png)

其中conv1d、2d、3d就是指在1、2、3维度进行卷积

点击某一个方法后，即可看到它的数学讲解和官方文档

![image-20220917094442350](typora-user-images\image-20220917094442350.png)

详细讲解conv2d的输入参数（parameters）：

![image-20220917100933496](typora-user-images\image-20220917100933496.png)

input：输入图像

weight：权重（就是卷积核）

bias：偏差

stride：步长（即卷积核移动的步数），可以是一个数，也可以是一个二元组（默认为1）

![image-20220917095629178](typora-user-images\image-20220917095629178.png)

padding：对input图像的边框进行填充，可以是一个数，也可以是一个二元组（默认为0）

（注意：填充的格子内部值为0！）

dilation：（暂时不讲）

groups：（暂时不讲）

## 2 图解卷积操作

就是相乘再相加

![image-20220917101440223](typora-user-images\image-20220917101440223.png)

## 3 代码实战（对图解进行代码验证）

1、pycharm中新建一个p17_nn_conv.py文件

2、初始化上图中的矩阵

```
import torch

input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 1, 2, 3, 1],
                      [1, 2, 1, 0, 0],
                      [5, 2, 3, 1, 1],
                      [2, 1, 0, 1, 1]])

kernel = torch.tensor([[1, 2, 1],
                       [0, 1, 0],
                       [2, 1, 0]])
```

3、由说明文档可知conv2d的input类型不仅仅是一个矩阵，而是必须包含“最小batch、通道数、高度、宽度”（即4个参数才行）

![image-20220917102620415](typora-user-images\image-20220917102620415.png)

因此我们需要对input和kernel进行变换（reshape）

```
input = torch.reshape(input, (1, 1, 5, 5)) # 1batchsize、1通道、5*5的矩阵
kernel = torch.reshape(kernel, (1, 1, 3, 3))
```

4、执行conv2d函数

```
import torch.nn.functional as F # 通用导入的方法，背会
output = F.conv2d(input, kernel, stride=1)
print(output)
```

5、完整代码：

```
import torch
import torch.nn.functional as F # 通用导入的方法，背会

# 初始化矩阵
input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 1, 2, 3, 1],
                      [1, 2, 1, 0, 0],
                      [5, 2, 3, 1, 1],
                      [2, 1, 0, 1, 1]])

kernel = torch.tensor([[1, 2, 1],
                       [0, 1, 0],
                       [2, 1, 0]])

# reshape,使得矩阵都符合conv2d函数的要求
input = torch.reshape(input, (1, 1, 5, 5)) # 1batchsize、1通道、5*5的矩阵
kernel = torch.reshape(kernel, (1, 1, 3, 3))

# 执行卷积操作conc2d
output = F.conv2d(input, kernel, stride=1)
print(output)
```

6、结果如下：

![image-20220917103314217](typora-user-images\image-20220917103314217.png)

7、若更改stride=2，则结果如下：

```
output = F.conv2d(input, kernel, stride=2)
```

![image-20220917103406563](typora-user-images\image-20220917103406563.png)

8、若添加1个padding（内部值为0,则input变为了6*6），结果如下：

```
output = F.conv2d(input, kernel, stride=1, padding=1)
```

![image-20220917103727413](typora-user-images\image-20220917103727413.png)

