# p18 神经网络-卷积层

## 1 官方文档查看

conv2d是用于二维卷积（即图片）因此使用最多

![image-20220917113810516](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917113810516.png)

参数的具体含义

![image-20220917114003166](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917114003166.png)

卷积更加清晰的官方讲解（带有动图的链接）

[conv_arithmetic/README.md at master · vdumoulin/conv_arithmetic (github.com)](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)

①这里的kernelsize是指卷积核的一个大小（内部的数不需要我们自己设置，这些值会在训练的过程中不断调整）

②in_channels是指输入图片的通道数量（一般为3，就是rgb）

③out_channels是指输出图片的通道数量（若out_channels=2，则生成两个卷积核进行卷积，然后得到2个输出）

![image-20220917115159038](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917115159038.png)



## 2 代码实战

 1、编写代码：

```
import torch
import torchvision
from torch import nn
from torch.nn import Conv2d
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# 导入并加载数据集
# 选择测试数据及（因为测试数据集图片少一点）
# 加载时将64个图片为一组
dataset = torchvision.datasets.CIFAR10("./dataset", train=False, transform=torchvision.transforms.ToTensor(),
                                       download=True)
dataloader = DataLoader(dataset, batch_size=64)

# 定义自己的模型类（定义之前先继承module父类）

class Lzp(nn.Module):
    def __init__(self):
        super(lzp, self).__init__() # 复现父类的初始化方法（必写）
        # 实体化卷积层的对象，输入通道为3，输出通道为6，卷积核大小为3，步长为1，padding为0
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)

    def forward(self,x): #编辑forward函数，模型的具体操作写在这里，x是input
        x = self.conv1(x) # 对输入进行一次卷积操作
        return x

# 实例化尝试以上的模型类
lzp = Lzp() # 实体化模型

# 成批量的对图片进行卷积操作
# 同时将每64张图片打印到tensorloader中
writer = SummaryWriter("./tensorWirter") # 定义打印文件的存放位置
step = 0
for data in dataloader:
    imgs, targets = data # 每一次for循环，获取64张图片和他们对应的标签
    output = lzp(imgs) # 每一次for循环，对64张图片成批地进行卷积操作
    print(imgs.shape) # 打印出的效果为： “torch.Size([64, 3, 32, 32])” 表示64个batchs，3通道，32*32的图片
    print(output.shape) # 打印出的效果为： “torch.Size([64, 6, 30, 30])” 表示64个batchs，6通道，30*30的图片

    writer.add_images("input", imgs, step)
    # 如果直接打印output图片时会报错，因为tensorloader函数只支持3通道（RGB格式的图片）进行打印，此时output为6通道，不可行
    # 因此，在打印output之前，先将其转化为3通道（reshape）
    # torchSize([64, 6, 30, 30]) -> ([xxx, 3, 30, 30])，这里的xxx会随着通道数的变化而变化，但是batch*channel的积是不变的，因此，这里batchsize会自动变为128！
    output = torch.reshape(output, (-1, 3, 30, 30)) # batch处填“-1”即可保证batchsize会随着通道的变化而动态变化
    writer.add_images("output", output, step)
    step = step + 1
```

2、运行，效果如下（最后一组图片没有64个，是因为默认设置余数是不丢弃的，即drop_last为false）

![image-20220917140511011](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917140511011.png)

3、在终端输入启动tensorloader的命令

```
tensorboard --logdir=tensorWirter
```

（补充，如何解决pycharm的terminal无法activate环境的问题）

[(140条消息) 关于pycharm终端无法通过activate命令进入虚拟环境的问题解决方案_煦風XOF的博客-CSDN博客_activate虚拟环境](https://blog.csdn.net/qq_43449643/article/details/125267134)

![image-20220917140840812](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917140840812.png)

![image-20220917141334954](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917141334954.png)

在浏览器中查看：

![image-20220917141507079](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917141507079.png)





# p19 神经网络-池化层（最大池化maxpool2d）

## 1 官方文档查看

[torch.nn — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/nn.html#pooling-layers)

![image-20220917142035194](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917142035194.png)

1、参数说明：

![image-20220917142157535](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917142157535.png)

kernel_size：池化核，类似于卷积核大小的定义

dilation:（这个卷积层的函数也有）含义如下图（一般不设置）

![image-20220917142456222](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917142456222.png)

ceil_model：含义如下图

![image-20220917142623997](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917142623997.png)

## 2 池化的含义讲解

```
!!!!!!!!!!池化层不设置步长，默认不重合！！！！！！！！
```



![image-20220917142950714](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917142950714.png)

这里ceil_model如果为true，这之后的2格也要判断

而ceil_model为false时，如果剩下的size<3，则直接舍去



## 3 代码编写（初阶使用，证明上图）

在pycharm中新建p19_nn_maxpool.py文件

重点就在：池化操作只能对float类型数据操作，long类型的数据进行池化时会报错！

```
import torch
from torch import nn
from torch.nn import MaxPool2d

# 初始化矩阵
input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 1, 2, 3, 1],
                      [1, 2, 1, 0, 0],
                      [5, 2, 3, 1, 1],
                      [2, 1, 0, 1, 1]],
                     dtype=torch.float32) # 这里必须将input内的数字变为float类型（原来是long类型，该类型不能进行池化操作！）

# reshape,使得矩阵都符合MaxPool2d函数的要求
input = torch.reshape(input, (-1, 1, 5, 5)) # batchsize为-1表示自动计算batchsize,1通道、5*5的矩阵,

# 定义模型类，定义池化操作方法
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)

    def forward(self, input):
        output = self.maxpool1(input)
        return output

# 执行池化操作MaxPool2d
tudui = Tudui()
output = tudui(input)
print(output)
```

效果如下：

![image-20220917145206583](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917145206583.png)



若此刻把ceil_mode设置为false，则结果中仅仅只有一个值了：

```
self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
```

![image-20220917145306738](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917145306738.png)



## 4 池化层的作用是什么

就是将原来的数据去其糟粕取其精华



## 5 代码编写（对图片的池化实战）

1、pycharm中的p19_nn_maxpool.py中编写

```
import torch
import torchvision
from torch import nn
from torch.nn import MaxPool2d
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# 导入，并加载数据集
dataset = torchvision.datasets.CIFAR10("./CIFAR10", transform=torchvision.transforms.ToTensor(),
                                       train=False, download=True)
dataloader = DataLoader(dataset, batch_size=64)

# 定义模型类，定义池化操作方法
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)

    def forward(self, input):
        output = self.maxpool1(input)
        return output

# 执行池化操作MaxPool2d
tudui = Tudui()

step = 0
writer = SummaryWriter("tensorLoader")
for data in dataloader:
    imgs, targets = data
    writer.add_images("input", imgs, step)
    imgs = tudui(imgs)
    writer.add_images("output", imgs, step) # 因为池化操作，不会影响通道的数量，所以直接打印即可，不需要变换
    step = step + 1

writer.close()
```

2、在终端启动打印网页

![image-20220917150727444](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917150727444.png)

3、效果入下：

![image-20220917150749129](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917150749129.png)



# p20 神经网络-非线性激活

## 1 官方文档

[torch.nn — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/nn.html)

![image-20220917154123895](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917154123895.png)

最常见的是relu，原理如下图：

[ReLU — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/generated/torch.nn.ReLU.html#torch.nn.ReLU)

![image-20220917154305807](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917154305807.png)

其次常用的是sigmoid，原理如下图

![image-20220917154436917](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917154436917.png)

## 2 以relu为例子做代码展示（数组）

1、ReLU的inplace参数的含义（表示原来的值是否能够替换，默认为false，即不替换）：

![image-20220917154954304](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917154954304.png)

2、代码展示

```
import torch
import torchvision
from torch import nn
from torch.nn import ReLU

# 初始化input
input = torch.Tensor([[1, -0.5],
                      [-1, 3]])
input = torch.reshape(input, (-1, 1, 2, 2)) # -1为batchsize，1为通道数量，2*2

# 定义自己的模型类
class Lzp(nn.Module):
    def __init__(self):
        super(Lzp, self).__init__()
        self.ReLU1 = ReLU() # 默认inplace为false，所以不需要写

    def forward(self, x):
        output = self.ReLU1(x)
        return output

# 使用自己的模型类，进行ReLU操作
lzp = Lzp()
output = lzp(input)
print(output)
```

3、结果显示

把所有的负数都变成0了

![image-20220917160109703](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917160109703.png)

## 3 以sigmoid为例子做代码展示（图片）

就是还是那一套模版化的东西，写多了就背会了：

```
import torch
import torchvision
from torch import nn
from torch.nn import ReLU, Sigmoid
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# 导入并加载数据集
dataset = torchvision.datasets.CIFAR10("./Cifar10", train=False, transform=torchvision.transforms.ToTensor(),
                                       download=True)
dataloader = DataLoader(dataset, batch_size=64)

# 定义自己的模型类
class Lzp(nn.Module):
    def __init__(self):
        super(Lzp, self).__init__()
        self.sigmoid = Sigmoid()

    def forward(self, x):
        output = self.sigmoid(x)
        return output

# 使用自己的模型类，进行ReLU操作
lzp = Lzp() # 实体化一个自己的类对象

writer = SummaryWriter("./tensorloader")
step = 0
for data in dataloader:
    imgs, targets = data
    writer.add_images("input", imgs, step)
    output = lzp(imgs)
    writer.add_images("output", output, step)

writer.close()
```

然后在终端打开浏览器的打印网页

效果如下：

![image-20220917161737873](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917161737873.png)



# p21 神经网络-线性层其他函数介绍

## 1 正则化层，以及batchnorm2d函数的介绍

[BatchNorm2d — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)

![image-20220917163632823](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917163632823.png)



## 2 Recurrent layers的介绍

[torch.nn — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/nn.html#recurrent-layers)

主要用于文字的训练



## 3 线性层Linear Layers（重点！）

### （1） 官方文档：

[Linear — PyTorch 1.8.1 documentation](https://pytorch.org/docs/1.8.1/generated/torch.nn.Linear.html#torch.nn.Linear)

①三个参数的含义

③weight和bias的含义

![image-20220917164713111](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917164713111.png)

先随便找个模型举个案例：

![image-20220917165502592](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917165502592.png)

### （2）代码实战

比如，我们想要把一个`5*5`的数据，线性变换为一个`1*25`的数据，然后再转化为`3*(25/3)`的数据

即：

```
5 -> 25 -> 3
```



![image-20220917170025760](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917170025760.png)

1、在pycharm中编写代码：

```
import torch
import torchvision
from torch import nn
from torch.nn import Linear
from torch.utils.data import DataLoader

# 导入并加载数据集
dataset = torchvision.datasets.CIFAR10("./Cifar10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=64)

# 自己设计自己的模型
class Lzp(nn.Module):
    def __init__(self):
        super(Lzp, self).__init__()
        # 实体化Linear类对象，这里的in_feature = 196608（就是每64张图片的数据参数的乘积）
        # out_feature = 10 是自己设计定的
        self.linear = Linear(in_features=196608, out_features=10, bias=True)

    def forward(self, x):
        output = self.linear(x)
        return output

# 实例化自己的模型，并利用实例化的模型对数据集进行线性变换
lzp = Lzp()
for data in dataloader:
    imgs, targets = data
    print(imgs.shape) # 这里打印得到的结果为：“torch.Size([64,3,32,32])”，无论怎么变化，这4个值的乘积是不会变化的，也就是196608

    # 以下的这两个方法，都是将高维的数据变为了一维数据
    # 不同之处在于：reshape方法其实仍然是4维的，只是将所有数据都集中在了第一个维度，所以看起来是一维的:“[1,1,1,196608]”
    # 而flatten方法是，实实在在地将4维度的数据直接压缩在了一维空间中:“[196608]”
    output = torch.reshape(imgs, (1, 1, 1, -1))
    # output = torch.flatten(imgs)
    print(output.shape)

    # 线性变换，“196608 -> 10”
    output = lzp(output)
    print(output.shape)
```

2、在`output = torch.reshape(imgs, (1, 1, 1, -1))`条件下的结果：

![image-20220917174121623](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917174121623.png)

3、在`output = torch.flatten(imgs)`条件下的结果：

![image-20220917174211406](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917174211406.png)





## 4 dropout层

用一定概率，来让tensor中某一个位置的值变为0

![image-20220917164045428](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917164045428.png)

## 5 其他Torchvision.model的经典模型代码

[torchvision.models — Torchvision master documentation (pytorch.org)](https://pytorch.org/vision/0.9/models.html)

这里有很多有名的模型：

![image-20220917174500580](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917174500580.png)



（补充：文字方面的在这里[torchtext — Torchtext 0.13.0 documentation (pytorch.org)](https://pytorch.org/text/stable/index.html)）

（语音方面的在这里：[Torchaudio Documentation — Torchaudio 0.12.1 documentation (pytorch.org)](https://pytorch.org/audio/stable/index.html)）

# p22 神经网络的搭建小实战、Sequential的使用

目标：对cifair10这个数据集进行分类（根据图片的内容来判断这个图片属于哪一类）

![image-20220917191818923](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917191818923.png)

其中：

convolution：卷积操作

max-pooling：最大池化

flatten：扁平化（降维操作）

fully connected：全连接层（linear操作）

```
重要！
一个全连接层包含了2个线性操作：
1、由1024（64*4*4） 的展平，转化为64个类别；
2、再由64个类，转化为10个类别，从而分出10个类别（CIFAR10这个数据库的图片就是10个类别）
```





## 1 实战代码——模型class的实现：

1、新建文件夹，和py文件

2、根据上图的处理结构来进行编写

①我们发现第一次卷积后的图片的h和w都不变，计算后得到stride和padding的值

![image-20220917192612457](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917192612457.png)

注意，这里是解二元一次方程，但是只有一个方程，因此解不唯一

这里假设stride = 1、2、3...... 尝试，最后用一个最合理的就可以了（尝试得到stride=1时最合理）

（多次计算发现规律，如果kernelSize=5，那么当卷积之后h和w都不变，则stride=1，padding=2）

②注意全连接层包含了两个linear（线性操作）（1024 -> 64 -> 10）

```
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear


class Lzp(nn.Module):
    def __init__(self): # 编写初始化函数，即各个操作类的实例化
        super(Lzp, self).__init__()
        # 卷积第一次
        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5,
                            stride=1, padding=2) # 我们发现第一次卷积后的图片的h和w都不变，计算后得到stride和padding的值
        # 池化第一次
        self.maxpool1 = MaxPool2d(kernel_size=2)
        # 卷积第二次
        self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5,
                            stride=1, padding=2) # 同样的，padding和stride都是解二元一次方程得到的（解不唯一）
        # 池化第二次
        self.maxpool2 = MaxPool2d(kernel_size=2)
        # 卷积第三次
        self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5,
                            stride=1, padding=2) # （多次计算发现规律，如果kernelSize=5，那么当卷积之后h和w都不变，则stride=1，padding=2）
        # 池化第三次
        self.maxpool3 = MaxPool2d(kernel_size=2)
        # 对数据进行展平
        self.flatten = Flatten()
        # 全连接层（包含两个linear），产生10个类别
        self.linear1 = Linear(in_features=1024, out_features=64)
        self.linear2 = Linear(in_features=64, out_features=10)

    def forward(self,x): # 编写forward函数，即各个实例化的类如何真正操作
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.conv3(x)
        x = self.maxpool3(x)
        x = self.flatten(x)
        x = self.linear1(x)
        x = self.linear2(x)
        return x

lzp = Lzp()
print(lzp)
```

模型的打印效果如下（可以看到和讲解图步骤一样）：

![image-20220917195149230](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917195149230.png)

## 2 实战代码——模型是否编写正确的检查

（其实就是检查卷积-池化-卷积-池化，这一过程中的参数是否首尾相接！）

写一个小demo来检查

torch提供了一个可以自动生成tensor的方法：

比如提供一个全是1的tensor张量：torch.ones((batchSize, Channel, height, weight))

```
lzp = Lzp()
input = torch.ones((64, 3, 32, 32))
output = lzp(input)
print(output.shape)
```

运行代码，如果能够正常打印出output的shape，则说明代码运行正确

![image-20220917201544916](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917201544916.png)



还有一种方法是debug



## 3 Sequential类的使用

sequential类就是一个可以将多个｛卷积-池化-卷积-池化。。。。｝等不同操作整合到一个实体类中的方法！



例如：

```
class Lzp(nn.Module):
    def __init__(self): # 编写初始化函数，即各个操作类的实例化
        super(Lzp, self).__init__()
        # 卷积第一次
        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5,
                            stride=1, padding=2) # 我们发现第一次卷积后的图片的h和w都不变，计算后得到stride和padding的值
        # 池化第一次
        self.maxpool1 = MaxPool2d(kernel_size=2)
        # 卷积第二次
        self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5,
                            stride=1, padding=2) # 同样的，padding和stride都是解二元一次方程得到的（解不唯一）
        # 池化第二次
        self.maxpool2 = MaxPool2d(kernel_size=2)
        # 卷积第三次
        self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5,
                            stride=1, padding=2) # （多次计算发现规律，如果kernelSize=5，那么当卷积之后h和w都不变，则stride=1，padding=2）
        # 池化第三次
        self.maxpool3 = MaxPool2d(kernel_size=2)
        # 对数据进行展平
        self.flatten = Flatten()
        # 全连接层（包含两个linear），产生10个batchsize，即10个类别
        self.linear1 = Linear(in_features=1024, out_features=64)
        self.linear2 = Linear(in_features=64, out_features=10)

    def forward(self,x): # 编写forward函数，即各个实例化的类如何真正操作
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.conv3(x)
        x = self.maxpool3(x)
        x = self.flatten(x)
        x = self.linear1(x)
        x = self.linear2(x)
        return x
```

就等价于：

```
class Lzp(nn.Module):
    def __init__(self): # 编写初始化函数，即各个操作类的实例化
        super(Lzp, self).__init__()
        self.sequential = nn.Sequential(
            Conv2d(in_channels=3, out_channels=32, kernel_size=5,
                   stride=1, padding=2),
            MaxPool2d(kernel_size=2),

            Conv2d(in_channels=32, out_channels=32, kernel_size=5,
                   stride=1, padding=2),
            MaxPool2d(kernel_size=2),

            Conv2d(in_channels=32, out_channels=64, kernel_size=5,
                    stride=1, padding=2),
            MaxPool2d(kernel_size=2),

            Flatten(),
            Linear(in_features=1024, out_features=64),
            Linear(in_features=64, out_features=10)
        )


    def forward(self,x): # 编写forward函数，即各个实例化的类如何真正操作
        x = self.sequential(x)
        return x
```



## 4 对这个模型的tensorboard的可视化（add_graph的使用）

这里不再打印数据集的数据（太多了）

直接打印`input = torch.ones((64, 3, 32, 32))`生成的这个图

此时，再介绍一个tensorloader的add_graph的方法：（这个方法就是用来展示模型的具体实现细节的）

它有2个参数：①model模型对象   ②input的图片

```
lzp = Lzp()
input = torch.ones((64, 3, 32, 32))
output = lzp(input)
print(output.shape)

writer = SummaryWriter("./tensorloader")
writer.add_graph(lzp, input)
writer.close()
```

运行，并启动打印端口，结果如下：

![image-20220917202822370](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917202822370.png)

双击模型、再双击sequential，结果如下：

![image-20220917202947201](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917202947201.png)

如果再点击某一个特定的方法对象，则会更加详细地展示细节

![image-20220917203046549](C:\Users\StarrySky\AppData\Roaming\Typora\typora-user-images\image-20220917203046549.png)